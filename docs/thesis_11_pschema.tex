\epigraph{\textit{Logic is the foundation of the certainty of all the Knowledge we acquire.}}{-- \textup{Leonhard Euler}}

The main goal of this thesis is to create a tool capable of creating subsets out of a Knowledge graph. In this chapter, we will explore the possibility of implementing the Pregel framework in Rust, as well as a novel approach to the problem of Knowledge graph validation.

\section{Pregel-rs}

The \texttt{pregel-rs} library is a Rust fork of the original Pregel framework that we have already discussed in chapter \ref{chapter:theory}. The library is available on GitHub\footnote{\url{https://github.com/angelip2303/pregel-rs}}.

\subsection{Design}

So far, we have discussed the Pregel framework. However, to implement it, we need to make certain design decisions. This section will outline the compromises we have made to successfully implement the Pregel framework using Rust.

First and foremost, it should be acknowledged that when transitioning from the Scala-based solution to the Rust-based one, we were fully aware that building the solution on top of existing projects would not be feasible. This stems from the fact that Rust, being a relatively new language, is not as mature as Java. Consequently, certain features would need to be developed from scratch. Thus, we initiated the development of the Pregel library, which will be utilized to implement the subgraph matching algorithm.

It is important to note that we have deliberately separated the framework from the algorithm implementation addressed in this thesis. This decision was made to maximize the framework's flexibility. By adopting this approach, not only can we utilize the framework in other projects, but we can also extend its capabilities to support additional features. To put an example, we have successfully incorporated the \textit{PageRank} algorithm into the framework as an additional feature to demonstrate its versatility. The subsequent section will provide a detailed description of this particular feature.

\subsubsection{The \texttt{pregel-rs} library}

Recall that Rust is heavily oriented to be executed in single machines. This means that we won't use the Pregel framework to process graphs in a distributed manner. Instead, we will use it to process graphs in a single machine. This is a reasonable approach since the main goal of this thesis is to create a tool capable of creating subsets out of a Knowledge graph. Thus, we will use the Pregel framework to implement the subgraph matching algorithm. With that being said, we will now describe the design of the \texttt{pregel-rs} library.

Firstly, we are describing the series of steps that the Pregel framework follows to process a graph. This sequence is depicted in figure \ref{fig:sequence}. The execution starts by sending the initial messages to the vertices at iteration 0. Then, the first -- actual -- superstep begins. This loop will last until the current iteration is greater than the threshold set at the creation of the Pregel instance. In each iteration, the vertices will send messages to their neighbors, provided the given direction, and subsequently, they receive messages sent by their neighbors. Moving forward, an aggregation function is applied, and the vertices are updated accordingly. Finally, the iteration counter is incremented, and the next iteration starts.

\begin{figure}[ht]
    \centering
    \includegraphics[width=0.33\textwidth]{diagrams/11-1_pregel.pdf}
    \label{fig:sequence}
    \caption{The Pregel framework as implemented in \texttt{pregel-rs}}
\end{figure}

As you can observe, this process is far from complex. We can agree that the Pregel framework is a simple abstraction for graph processing. However, this simplicity is what makes the Pregel so powerful. By abstracting the underlying model, we can focus on the problem at hand, rather than the implementation details of the framework. By doing so, we can focus on the implementation of the subgraph matching algorithm, rather than the implementation details of the Pregel model itself.

\subsubsection{The Builder pattern}

In Rust, there is no direct support for constructors. Instead, the convention is to use an associated function called \texttt{new} that returns an instance of the \texttt{struct}. However, this approach limits us to creating only one representation of the object since multiple functions cannot have the same identifier. To overcome this limitation and enable the creation of different representations of the same object, we can utilize the \textit{Builder pattern}.

The Builder pattern is a creational design pattern that allows us to decouple the construction of a complex object from its functionality. By separating the construction process, we gain the flexibility to create diverse representations of the object. This pattern effectively resolves the issue of dealing with constructors that have an excessive number of parameters and also addresses Rust's limitation of having multiple constructors with the same name. Lastly, it also allows us to \textit{create} objects in a -- somewhat -- functional manner, which is a common practice in Rust.

\begin{figure}[ht]
    \centering
    \includegraphics[width=0.66\textwidth]{diagrams/11-2_builder.png}
    \caption[The Builder pattern as implemented in \texttt{pregel-rs}]{The Builder pattern as implemented in \texttt{pregel-rs}\footnotemark}
\end{figure}
\footnotetext{\url{https://refactoring.guru/design-patterns/builder}}

\subsection{Implementation}

We will now discuss the implementation details of the Pregel library that we have just described. Recall that we are willing to create a tool that is implemented on top of a DataFrame API, as we want to leverage the benefits of this abstraction that we have already discussed in chapter \ref{chapter:refactoring}. Thus, we will now describe the implementation details of the Pregel library.

\subsubsection{The \texttt{GraphFrame} struct}

The first step is to create a representation of the graph that we are going to process. To do so, we have created the \texttt{GraphFrame} struct. This struct is a wrapper around the \texttt{pola-rs} \texttt{DataFrame} library, which is the Rust equivalent to Apache Spark, as we have seen in chapter \ref{chapter:analysis}. This struct is responsible for storing the graph's vertices and edges, as well as extending its basic functionality to support some useful operations. For instance, we have implemented the \texttt{from\_edges} function, which is responsible for creating a \texttt{GraphFrame} instance from a set of edges. This function is useful since we can create the \texttt{GraphFrame} from the edges that we have extracted from the Knowledge graph in chapter \ref{chapter:wd2duckdb}.

\begin{code}[GraphFrame implementation in \texttt{pregel-rs}]
    \inputminted{rust}{code/listings/11-1_graph.rs}
\end{code}

\section{PSchema-rs}

\subsection{The algorithm in a nutshell}

In this section, we will describe the algorithm that we are using to validate the Knowledge graph. The idea is to transform the given set of rules, \texttt{Shape} \texttt{Expression}, into a tree that is going to be traversed by the Pregel model that we have just described, namely, the subgraph matching algorithm. This idea takes inspiration from the \textit{Distributed subgraph matching algorithm} presented in \cite{Xu2019}; however, several modifications are introduced due to the requirements of our project.

\subsubsection{The \texttt{Shape} \texttt{Expression} tree}

Given a \texttt{Shape} \texttt{Expression} schema $\mathcal{S}$, we assume that it is a collection of labeled \texttt{Shape} \texttt{Expressions} that describe an RDF graph in terms of two main syntactic components\footnote{\url{https://shex.io/shex-primer/}}: \texttt{Triple Constraints}, \texttt{Shape References} and \texttt{Groupings of Triple Constraints}. The former is a triple pattern that describes a predicate-subject statement matched by the sub-setting algorithm. The second is another triple constraint where the subject is a reference to a \texttt{Shape}. The latter is a grouping of several of those constraints. The \texttt{Shape} \texttt{Expression} schema is going to be transformed into a tree, called \texttt{Shape} \texttt{Expression} tree, that is going to be traversed by the validation algorithm. This tree is going to be built recursively, and it is going to be traversed in a bottom-up fashion. This means that we are going to start by validating the leaves and then we are going to build the internal nodes, that is, the tree is going to be traversed in a \textit{reverse level order} fashion, as we need the children validated first for us to validate their parents. This is going to be done by an \texttt{iterator} that we will describe later on.

Putting this all together, \texttt{Shape} \texttt{Expressions} can be divided into two main categories according to the tree that they are going to generate, namely, \texttt{unary} and \texttt{n-ary} components. The former is going to generate a tree with a single node labeled with the identifier of the \texttt{Triple Constraint}, or, a single node with a single child in the case of a \texttt{Shape Reference}. The latter is going to generate a tree with a single node labeled with the identifier of the \texttt{Shape} that wraps the \texttt{Grouping} and with $n$ children. For each of the children, we are going to build their corresponding \texttt{Shape} \texttt{Expression} tree. This is going to be done recursively. For more information, see the \texttt{Shape} \texttt{Expression} tree definition.

\begin{definition}
    The \texttt{Shape} \texttt{Expression} tree $T$ is defined as follows. Having $\mathcal{S}$ a \texttt{Shape}, two main cases are possible:

    \begin{itemize}
        \itemsep0.5em
        \item If $\mathcal{S}$ is a \textit{unary} component, two cases are possible:
              \begin{itemize}
                  \itemsep0.25em
                  \item If $\mathcal{S}$ is a \texttt{Triple} \texttt{Constraint}, then $\mathcal{T}$ is a tree with a single node labeled with the identifier of the \texttt{Shape}.
                  \item If $\mathcal{S}$ is a \texttt{Shape Reference}, then $\mathcal{T}$ is a tree with a single node labeled with the identifier of the $\mathcal{S}$ shape and with a single child, $\mathcal{T}_1$, which is the \texttt{Shape} \texttt{Expression} tree of $\mathcal{S}_1$.
              \end{itemize}
        \item If $\mathcal{S}$ is a \textit{n-ary} component, one case is possible:
              \begin{itemize}
                  \itemsep0.25em
                  \item If $\mathcal{S}$ wraps a group of \texttt{Shapes}, then $\mathcal{T}$ is a tree with a single node labeled with the identifier of the $\mathcal{S}$ shape and with $n$ children,$\{\mathcal{T}_1, \mathcal{T}_2, ..., \mathcal{T}_n\}$, which are the \texttt{Shape} \texttt{Expression} trees of $\{\mathcal{S}_1, \mathcal{S}_2, ..., \mathcal{S}_n\}$, respectively.
              \end{itemize}
    \end{itemize}

    Note that the \texttt{Shape} \texttt{Expression} tree is going to be built recursively. Hence, the base case is the first item of this definition, and the recursive cases are the other two. In this manner, by chaining recursive cases, we can build a tree with an arbitrary depth.
\end{definition}

Following into this definition, we have only implemented part of the \texttt{Shape} \texttt{Expression} model as it is out of the scope of the project; recall, we are mainly interested in the \texttt{Triple} \texttt{Constraint} component. However, it is easy to extend the implementation to support the other components. For more information, see the \texttt{Shape} \texttt{Expression} model implementation in \texttt{pschema-rs}\footnote{\url{https://github.com/angelip2303/pschema-rs/issues/1}}.

\begin{table}[ht]
    \centering
    \begin{tabular}{|l|c|l|c|}
        \hline
        \rowcolor[HTML]{C0C0C0}
        \multicolumn{1}{|c|}{\cellcolor[HTML]{C0C0C0}\textbf{Feature}} & \textbf{Supported}         & \multicolumn{1}{c|}{\cellcolor[HTML]{C0C0C0}\textbf{PSchema Representation}} & \multicolumn{1}{c|}{\cellcolor[HTML]{C0C0C0}\textbf{Tree Category}} \\ \hline
        Triple and Node Constraints                                    & {\color[HTML]{009901} Yes} & \texttt{Triple Constraint}                                                   & Unary                                                               \\ \hline
        Grouping                                                       & {\color[HTML]{009901} Yes} & \texttt{ShapeAnd}                                                            & N-ary                                                               \\ \hline
        Nesting Shapes                                                 & {\color[HTML]{009901} Yes} & \multicolumn{1}{c|}{$\cdots$}                                                & \multicolumn{1}{c|}{$\cdots$}                                       \\ \hline
        Built-in DataTypes                                             & {\color[HTML]{009901} Yes} & \texttt{ShapeLiteral}                                                        & Unary                                                               \\ \hline
        Shape Reference                                                & {\color[HTML]{009901} Yes} & \texttt{ShapeReference}                                                      & Unary                                                               \\ \hline
        Literal facets                                                 & {\color[HTML]{FE0000} No}  & \multicolumn{1}{c|}{$\cdots$}                                                & \multicolumn{1}{c|}{$\cdots$}                                       \\ \hline
        Node Kind                                                      & {\color[HTML]{FE0000} No}  & \multicolumn{1}{c|}{$\cdots$}                                                & \multicolumn{1}{c|}{$\cdots$}                                       \\ \hline
        Value set                                                      & {\color[HTML]{FE0000} No}  & \multicolumn{1}{c|}{$\cdots$}                                                & \multicolumn{1}{c|}{$\cdots$}                                       \\ \hline
        Cardinalities                                                  & {\color[HTML]{009901} Yes} & \texttt{Cardinality}                                                         & N-ary                                                               \\ \hline
        Logical AND                                                    & {\color[HTML]{009901} Yes} & \texttt{ShapeAnd}                                                            & N-ary                                                               \\ \hline
        Logical OR                                                     & {\color[HTML]{009901} Yes} & \texttt{ShapeOr}                                                             & N-ary                                                               \\ \hline
        Regular Expressions                                            & {\color[HTML]{FE0000} No}  & \multicolumn{1}{c|}{$\cdots$}                                                & \multicolumn{1}{c|}{$\cdots$}                                       \\ \hline
    \end{tabular}
    \caption{Supported features of the \texttt{Shape} \texttt{Expression} implementation in \texttt{pschema-rs}}
\end{table}

\begin{example}
    Following the definition of the \texttt{Shape} \texttt{Expression} tree, we are going to build the tree of the \texttt{Shape} \texttt{Expression} presented in example \ref{code:shex}.
    \vskip 0.5em
    \begin{minipage}{0.45\textwidth}
        \inputminted{shexc}{code/listings/6-4_shex.shex}
    \end{minipage}
    \begin{minipage}{0.45\textwidth}
        \includestandalone[width=\textwidth]{diagrams/11-3_tree}
    \end{minipage}
\end{example}

Note that nothing is said about the order of the children of the nodes. This is because the order of those won't matter for the validation of the Knowledge graph, as the \texttt{Shape} \texttt{Expression} is a set of rules, and the order of the rules is not relevant. Hence, the order of the children of the nodes does not matter either. Do not confuse this with the order in which the different depth levels of the tree are traversed. This is going to be discussed later on.

\subsubsection{The \texttt{Shape} \texttt{Expression} tree traversal}

The tree is going to be traversed in a bottom-up fashion. This means that we are going to start by validating the leaves and then we are going to build the internal nodes, that is, the tree is going to be traversed in a \textit{reverse level order} manner. The reason for this is that we want to validate the leaves first because they are the ones that are going to be used for validating their parents. This is going to be done by an \texttt{iterator} that we will describe later on.

For us to better understand the traversal of the tree, we are going to use the following example:

\begin{example}
    \begin{figure}[ht]
        \centering
        \includestandalone[width=0.5\textwidth]{diagrams/11-4_traversal}
        \caption{Example of a reverse level order traversal of a tree}
        \label{fig:tree_traversal}
    \end{figure}
\end{example}

\subsubsection{The sub-graph matching algorithm}

The sub-graph matching algorithm that is going to be used for validating the Knowledge graph will traverse the Knowledge graph in a Pregel fashion and check whether the current node matches the \texttt{Shape} that is being validated. This is going to be done by the \texttt{iterator} that we have just described. According to this, it can be seen that several procedures should be considered; that is, we must properly define the following characteristics of the Pregel algorithm:

\begin{itemize}
    \itemsep0.5em
    \item The maximum number of iterations we want the algorithm to perform. If possible, we should establish an upper limit for the validation algorithm to iterate. As each superstep will possibly be a resource-heavy task, the lower the number of iterations, the better.
    \item At the beginning of the algorithm's execution an initial message is sent to all the nodes in the graph. After that, the first superstep is triggered.
    \item Both the message and the direction they follow are required to be defined. That is, we should establish a mechanism for nodes to know whether their neighbors conform to a certain \texttt{Shape} or not.
    \item As nodes may have several neighbors, a function for aggregating the set of messages having the node as the destination is also required.
    \item Having all the messages received and properly aggregated, the node should update its state according to what it has just collected.
\end{itemize}

\begin{pseudocode}[The PSchema algorithm as implemented in Rust]
    \includestandalone{code/algorithms/11-1_pschema}
\end{pseudocode}

\begin{theorem}
    Given a \texttt{Shape} \texttt{Expression} tree $\mathcal{T}$ and a Knowledge graph $\mathcal{G}$, let $h$ denote the height of $\mathcal{T}$; then if $h = 1$ the Pregel algorithm, denoted as $\mathcal{P}$, is going to validate the Knowledge graph $\mathcal{G}$ against $\mathcal{T}$ in $1$ superstep. If $h > 1$, then $\mathcal{P}$ is going to validate $\mathcal{G}$ against $\mathcal{T}$ in $h - 1$ supersteps. Formally, we can define the number of supersteps as follows:

    \begin{equation}
        \texttt{supersteps}(\mathcal{T}, \mathcal{G}) =
        \begin{cases}
            h     & \texttt{if } s = unary, \forall s \in \mathcal{T} \\
            h - 1 & \texttt{otherwise}
        \end{cases}
    \end{equation}
\end{theorem}

\begin{proof}
    Let us have $h$ the height of a \texttt{Shape} \texttt{Expression} tree $\mathcal{T}$, and let us denote $d_i$ the depth of the node $i$ in $\mathcal{T}$. Hence, at the superstep $h - d_i$, all the nodes at depth $d_i$ are going to be validated. As we traverse the tree in a \textit{reverse level order}, the previous definition holds. Hence, at the first superstep, the leaves are going to be validated, that is, at superstep 1, all the nodes at depth $h - 1$ are going to be validated. Then, at superstep 2, all the nodes at depth $h - 2$ are going to be validated; this is, at superstep $i$ nodes at depth $h - i$ are going to be validated. Thus, the tree is going to be traversed in $h$ supersteps. As the root is validated at the superstep $h - 0 = h$; note that the depth of the root node is 0, then, it can be seen that the tree is going to be traversed in $h$ supersteps.
\end{proof}

\subsection{Design}

\subsubsection{The \texttt{Iterator}}

\subsubsection{The \texttt{Validate} \texttt{trait}}

\subsubsection{Designing the \texttt{Shape} \texttt{Expressions}}

\paragraph{The \texttt{Shape} \texttt{Expression} \texttt{Composite}}

\paragraph{The \texttt{Shape} \texttt{Expression} \texttt{Adapter}}

\subsection{Optimizations}

\subsubsection{Parallelization}

The first optimization that we are going to consider is parallelization. The idea is to split the DuckDB dump into several chunks and then parse each of the chunks in parallel. This is going to be done by the first component of the tool. For this purpose, we are using \texttt{rayon}\footnote{\url{https://github.com/rayon-rs/rayon}}. This library is a data-parallelism API for Rust that provides several parallel iterators. Hence, we are using one to traverse the database in parallel. This can be done because each of the lines of the chunks of the dump is independent of each other. Thus, we can parse each of the entities in parallel without having to worry about synchronization issues. What's more, the \texttt{rayon} library is going to take care of the load balancing for us. This means that we do not have to worry about splitting the DuckDB dump into chunks of equal size. Lastly, \texttt{rayon} is also in charge of handling the thread pool for us and caring about the data races that might arise.

What I like the most about \texttt{rayon} is the ease of transforming a sequential iterator into a parallel one. Let's have a look at an example of how this can be done:

\begin{minted}{rust}
    let lines = BufReader::new(file).lines();
    let lines = lines.into_par_iter();
\end{minted}

Whereas the first line creates a sequential iterator, the second one transforms it into a parallel one. This is done by calling the \texttt{into\_par\_iter} method on the iterator. Even if we have just shown a simple example, the actual solution is not far from what we have just shown above. See the code in the repository\footnote{\url{https://github.com/angelip2303/pschema-rs/blob/main/src/backends/duckdb.rs\#L64}} for a more detailed example:

\begin{code}[Parallel iterator over the DuckDB dump]
    \inputminted{rust}{code/listings/11-2_duckdb.rs}
\end{code}